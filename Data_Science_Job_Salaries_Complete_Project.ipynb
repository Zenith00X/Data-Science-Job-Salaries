{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Science Job Salaries: End-to-End Analysis & Prediction\n",
        "\n",
        "**Project Objective:** Analyze and model data science job salaries to uncover salary trends, identify drivers, and predict salaries based on job- and role-related factors.\n",
        "\n",
        "**Domain:** Finance Analyst / Data Science  \n",
        "**Difficulty Level:** Intermediate  \n",
        "**Tools:** Python, Machine Learning (scikit-learn), pandas, Visualization (matplotlib, seaborn)\n",
        "\n",
        "---\n",
        "\n",
        "## Checklist of Deliverables\n",
        "\n",
        "- \u2705 **Load & validate dataset:** Download from Google Drive, check structure, handle errors\n",
        "- \u2705 **Data cleaning:** Handle missing values, standardize categories, convert codes to full names (EN\u2192Entry, remote_ratio\u2192job_type)\n",
        "- \u2705 **Feature engineering:** Encode categoricals, create salary_ratio, compute group statistics\n",
        "- \u2705 **Exploratory Data Analysis:** 10+ visualizations with error handling (distributions, trends by experience/employment/company size/job type)\n",
        "- \u2705 **Financial modeling:** Linear Regression to predict salary_in_usd, train/test split (80/20), MAE/MSE metrics\n",
        "- \u2705 **Dashboard concepts:** Example table structures for Streamlit (summary stats, filtering examples)\n",
        "- \u2705 **Insights summary:** Markdown bullet points on salary drivers and recommendations\n",
        "- \u2705 **Professional notebook:** Clear structure, step headings, inline error handling, reproducible code\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Problem Definition\n",
        "\n",
        "**Objective:** Analyze and model data science job salaries to uncover trends, identify salary drivers, and predict salaries based on job- and role-related factors.\n",
        "\n",
        "**Key Research Questions:**\n",
        "1. How do salaries vary by experience level, employment type, company size, and job type (remote/hybrid/onsite)?\n",
        "2. Which job titles command the highest salaries?\n",
        "3. Which countries/locations offer the best compensation for data science roles?\n",
        "4. Can we build a predictive model for salary estimation?\n",
        "5. What factors have the strongest influence on salary determination?\n",
        "\n",
        "**Data Dictionary:**\n",
        "- `work_year`: Year the salary was paid\n",
        "- `experience_level`: EN (Entry) / MI (Mid) / SE (Senior) / EX (Executive)\n",
        "- `employment_type`: PT (Part-time) / FT (Full-time) / CT (Contract) / FL (Freelance)\n",
        "- `job_title`: Role title (e.g., Data Scientist, Analyst)\n",
        "- `salary`: Total gross salary amount\n",
        "- `salary_currency`: Currency code (ISO 4217)\n",
        "- `salary_in_usd`: Salary converted to USD\n",
        "- `employee_residence`: Employee country (ISO 3166)\n",
        "- `remote_ratio`: 0 (On-site) / 50 (Hybrid) / 100 (Fully Remote)\n",
        "- `company_location`: Employer country (ISO 3166)\n",
        "- `company_size`: S (Small <50) / M (Medium 50-250) / L (Large >250)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Load and Understand Dataset\n",
        "\n",
        "Load the data, display structure, and check for initial issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set visualization defaults\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette('husl')\n",
        "\n",
        "print(\"Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download dataset from Google Drive\n",
        "try:\n",
        "    import gdown\n",
        "    url = 'https://drive.google.com/file/d/1jlayA_UP3pcYdD2zkL_bd2KcPpFHu_ad/view?usp=sharing'\n",
        "    file_id = url.split('/d/')[1].split('/')[0]\n",
        "    download_url = f'https://drive.google.com/uc?id={file_id}'\n",
        "    \n",
        "    df = pd.read_csv(download_url)\n",
        "    print(f\"\u2713 Dataset loaded successfully!\")\n",
        "    print(f\"  Shape: {df.shape[0]} rows \u00d7 {df.shape[1]} columns\")\nexcept Exception as e:\n",
        "    print(f\"\u26a0 Note: Could not download from Google Drive. Using example data structure.\")\n",
        "    print(f\"  Error: {str(e)}\")\n",
        "    # If download fails, create a note (in production, user would provide CSV file)\n",
        "    df = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If dataframe exists, display basic info\n",
        "if df is not None:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"DATASET OVERVIEW\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"\\nDataset Shape: {df.shape}\")\n",
        "    print(f\"\\nData Types:\")\n",
        "    print(df.dtypes)\n",
        "    print(f\"\\nFirst 5 Rows:\")\n",
        "    print(df.head())\n",
        "    print(f\"\\nMissing Values:\")\n",
        "    print(df.isnull().sum())\n",
        "else:\n",
        "    print(\"\u26a0 ERROR: Dataset could not be loaded.\")\n",
        "    print(\"Please ensure:\")\n",
        "    print(\"1. Internet connection is active\")\n",
        "    print(\"2. Google Drive link is accessible\")\n",
        "    print(\"3. 'gdown' library is installed (pip install gdown)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Data Cleaning\n",
        "\n",
        "Handle missing values, standardize categories, remove duplicates, and convert codes to meaningful names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df is not None:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"DATA CLEANING PROCESS\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # Create a copy for cleaning\n",
        "    df_clean = df.copy()\n",
        "    \n",
        "    # 1. Drop unnecessary columns\n",
        "    if 'Unnamed: 0' in df_clean.columns:\n",
        "        df_clean.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "        print(\"\\n\u2713 Dropped 'Unnamed: 0' column\")\n",
        "    \n",
        "    # 2. Remove duplicates\n",
        "    duplicates_before = len(df_clean)\n",
        "    df_clean.drop_duplicates(inplace=True)\n",
        "    duplicates_removed = duplicates_before - len(df_clean)\n",
        "    print(f\"\u2713 Removed {duplicates_removed} duplicate rows\")\n",
        "    print(f\"  Remaining rows: {len(df_clean)}\")\n",
        "    \n",
        "    # 3. Handle missing values\n",
        "    print(f\"\\n\u2713 Handling missing values:\")\n",
        "    for col in df_clean.columns:\n",
        "        if df_clean[col].isnull().sum() > 0:\n",
        "            if df_clean[col].dtype in ['int64', 'float64']:\n",
        "                df_clean[col].fillna(df_clean[col].median(), inplace=True)\n",
        "                print(f\"  - {col}: filled with median\")\n",
        "            else:\n",
        "                df_clean[col].fillna('Unknown', inplace=True)\n",
        "                print(f\"  - {col}: filled with 'Unknown'\")\n",
        "    \n",
        "    print(f\"\\n  Final missing values: {df_clean.isnull().sum().sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df is not None:\n",
        "    # 4. Convert codes to full names\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"CONVERTING CODES TO FULL NAMES\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # Experience Level\n",
        "    if 'experience_level' in df_clean.columns:\n",
        "        experience_map = {\n",
        "            'EN': 'Entry',\n",
        "            'MI': 'Mid',\n",
        "            'SE': 'Senior',\n",
        "            'EX': 'Executive'\n",
        "        }\n",
        "        df_clean['experience_level'] = df_clean['experience_level'].map(experience_map)\n",
        "        print(f\"\\n\u2713 Experience Level conversion:\")\n",
        "        print(df_clean['experience_level'].value_counts())\n",
        "    \n",
        "    # Employment Type\n",
        "    if 'employment_type' in df_clean.columns:\n",
        "        employment_map = {\n",
        "            'PT': 'Part-time',\n",
        "            'FT': 'Full-time',\n",
        "            'CT': 'Contract',\n",
        "            'FL': 'Freelance'\n",
        "        }\n",
        "        df_clean['employment_type'] = df_clean['employment_type'].map(employment_map)\n",
        "        print(f\"\\n\u2713 Employment Type conversion:\")\n",
        "        print(df_clean['employment_type'].value_counts())\n",
        "    \n",
        "    # Company Size\n",
        "    if 'company_size' in df_clean.columns:\n",
        "        size_map = {\n",
        "            'S': 'Small',\n",
        "            'M': 'Medium',\n",
        "            'L': 'Large'\n",
        "        }\n",
        "        df_clean['company_size'] = df_clean['company_size'].map(size_map)\n",
        "        print(f\"\\n\u2713 Company Size conversion:\")\n",
        "        print(df_clean['company_size'].value_counts())\n",
        "    \n",
        "    # Remote Ratio \u2192 Job Type\n",
        "    if 'remote_ratio' in df_clean.columns:\n",
        "        remote_map = {\n",
        "            0: 'Onsite',\n",
        "            50: 'Hybrid',\n",
        "            100: 'Remote'\n",
        "        }\n",
        "        df_clean['job_type'] = df_clean['remote_ratio'].map(remote_map)\n",
        "        df_clean.drop('remote_ratio', axis=1, inplace=True)\n",
        "        print(f\"\\n\u2713 Remote Ratio \u2192 Job Type conversion:\")\n",
        "        print(df_clean['job_type'].value_counts())\n",
        "    \n",
        "    # Standardize categorical columns (case consistency)\n",
        "    for col in ['job_title', 'company_location', 'employee_residence']:\n",
        "        if col in df_clean.columns:\n",
        "            df_clean[col] = df_clean[col].str.title()\n",
        "    \n",
        "    print(f\"\\n\u2713 Standardized categorical columns to Title Case\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df is not None:\n",
        "    # Keep both salary and salary_in_usd; rename salary_in_usd for clarity\n",
        "    print(f\"\\n\" + \"=\"*80)\n",
        "    print(\"SALARY COLUMNS HANDLING\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    if 'salary' in df_clean.columns and 'salary_in_usd' in df_clean.columns:\n",
        "        print(f\"\\n\u2713 Both 'salary' and 'salary_in_usd' columns retained\")\n",
        "        print(f\"  - Original salary (various currencies): mean = ${df_clean['salary'].mean():,.0f}\")\n",
        "        print(f\"  - Salary in USD: mean = ${df_clean['salary_in_usd'].mean():,.0f}\")\n",
        "    \n",
        "    print(f\"\\n\u2713 Data cleaning completed!\")\n",
        "    print(f\"  Final dataset shape: {df_clean.shape}\")\n",
        "    print(f\"\\nCleaned Dataset Columns:\")\n",
        "    print(df_clean.columns.tolist())\n",
        "    print(f\"\\nFirst 3 rows of cleaned data:\")\n",
        "    print(df_clean.head(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Feature Engineering\n",
        "\n",
        "Create encoded numerical representations and derived features for modeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df is not None:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"FEATURE ENGINEERING\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    df_features = df_clean.copy()\n",
        "    \n",
        "    # 1. Create numerical encodings for categorical variables\n",
        "    print(f\"\\n\u2713 Creating numerical encodings for categorical variables:\")\n",
        "    \n",
        "    # Experience level encoding\n",
        "    experience_encode = {'Entry': 1, 'Mid': 2, 'Senior': 3, 'Executive': 4}\n",
        "    df_features['experience_level_num'] = df_features['experience_level'].map(experience_encode)\n",
        "    print(f\"  - experience_level_num: {experience_encode}\")\n",
        "    \n",
        "    # Employment type encoding\n",
        "    employment_encode = {'Part-time': 1, 'Freelance': 2, 'Full-time': 3, 'Contract': 4}\n",
        "    df_features['employment_type_num'] = df_features['employment_type'].map(employment_encode)\n",
        "    print(f\"  - employment_type_num: {employment_encode}\")\n",
        "    \n",
        "    # Company size encoding\n",
        "    size_encode = {'Small': 1, 'Medium': 2, 'Large': 3}\n",
        "    df_features['company_size_num'] = df_features['company_size'].map(size_encode)\n",
        "    print(f\"  - company_size_num: {size_encode}\")\n",
        "    \n",
        "    # Job type (remote ratio) encoding\n",
        "    job_type_encode = {'Onsite': 0, 'Hybrid': 50, 'Remote': 100}\n",
        "    df_features['job_type_num'] = df_features['job_type'].map(job_type_encode)\n",
        "    print(f\"  - job_type_num: {job_type_encode}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df is not None:\n",
        "    # 2. Create derived features\n",
        "    print(f\"\\n\u2713 Creating derived features:\")\n",
        "    \n",
        "    # Salary ratio (if both columns exist)\n",
        "    if 'salary' in df_features.columns and 'salary_in_usd' in df_features.columns:\n",
        "        # Avoid division by zero\n",
        "        df_features['salary_ratio'] = np.where(\n",
        "            df_features['salary_in_usd'] != 0,\n",
        "            df_features['salary'] / df_features['salary_in_usd'],\n",
        "            1.0\n",
        "        )\n",
        "        print(f\"  - salary_ratio: (original salary / salary_in_usd)\")\n",
        "        print(f\"    Mean ratio: {df_features['salary_ratio'].mean():.4f}\")\n",
        "    \n",
        "    # 3. Group statistics by company_size and job_type\n",
        "    print(f\"\\n\u2713 Group statistics by Company Size and Job Type:\")\n",
        "    \n",
        "    company_size_stats = df_features.groupby('company_size').agg({\n",
        "        'salary_in_usd': ['mean', 'count']\n",
        "    }).round(2)\n",
        "    company_size_stats.columns = ['mean_salary', 'num_openings']\n",
        "    print(f\"\\n  Company Size Analysis:\")\n",
        "    print(company_size_stats)\n",
        "    \n",
        "    job_type_stats = df_features.groupby('job_type').agg({\n",
        "        'salary_in_usd': ['mean', 'count']\n",
        "    }).round(2)\n",
        "    job_type_stats.columns = ['mean_salary', 'num_openings']\n",
        "    print(f\"\\n  Job Type Analysis:\")\n",
        "    print(job_type_stats)\n",
        "    \n",
        "    print(f\"\\n\u2713 Feature engineering completed!\")\n",
        "    print(f\"  New numerical features created: experience_level_num, employment_type_num, company_size_num, job_type_num, salary_ratio\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Exploratory Data Analysis (EDA)\n",
        "\n",
        "Create comprehensive visualizations to understand salary trends and patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df is not None:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"EXPLORATORY DATA ANALYSIS (EDA)\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    print(\"\\nGenerating 10 visualizations...\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization 1: Salary Distribution\n",
        "if df is not None:\n",
        "    try:\n",
        "        fig, ax = plt.subplots(figsize=(12, 5))\n",
        "        sns.histplot(data=df_features, x='salary_in_usd', bins=30, kde=True, \n",
        "                     color='steelblue', edgecolor='black', ax=ax)\n",
        "        ax.set_title('Visualization 1: Salary Distribution (USD)', fontsize=14, fontweight='bold')\n",
        "        ax.set_xlabel('Salary in USD', fontsize=11)\n",
        "        ax.set_ylabel('Frequency', fontsize=11)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        print(\"\u2713 Visualization 1 rendered successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"\u26a0 Error rendering Visualization 1: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization 2: Salary vs Experience Level (bar + violin)\n",
        "if df is not None:\n",
        "    try:\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "        \n",
        "        # Bar plot\n",
        "        exp_order = ['Entry', 'Mid', 'Senior', 'Executive']\n",
        "        mean_salary_exp = df_features.groupby('experience_level')['salary_in_usd'].mean().reindex(exp_order)\n",
        "        sns.barplot(x=mean_salary_exp.index, y=mean_salary_exp.values, palette='Set2', ax=axes[0])\n",
        "        axes[0].set_title('Mean Salary by Experience Level', fontsize=12, fontweight='bold')\n",
        "        axes[0].set_xlabel('Experience Level', fontsize=11)\n",
        "        axes[0].set_ylabel('Mean Salary (USD)', fontsize=11)\n",
        "        axes[0].tick_params(axis='x', rotation=45)\n",
        "        \n",
        "        # Violin plot\n",
        "        sns.violinplot(data=df_features, x='experience_level', y='salary_in_usd', \n",
        "                       order=exp_order, palette='Pastel1', ax=axes[1])\n",
        "        axes[1].set_title('Salary Distribution by Experience Level', fontsize=12, fontweight='bold')\n",
        "        axes[1].set_xlabel('Experience Level', fontsize=11)\n",
        "        axes[1].set_ylabel('Salary (USD)', fontsize=11)\n",
        "        axes[1].tick_params(axis='x', rotation=45)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        print(\"\u2713 Visualization 2 rendered successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"\u26a0 Error rendering Visualization 2: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization 3: Salary vs Employment Type (bar + box)\n",
        "if df is not None:\n",
        "    try:\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "        \n",
        "        # Bar plot\n",
        "        emp_order = ['Part-time', 'Freelance', 'Full-time', 'Contract']\n",
        "        mean_salary_emp = df_features.groupby('employment_type')['salary_in_usd'].mean().reindex(emp_order)\n",
        "        sns.barplot(x=mean_salary_emp.index, y=mean_salary_emp.values, palette='Pastel1', ax=axes[0])\n",
        "        axes[0].set_title('Mean Salary by Employment Type', fontsize=12, fontweight='bold')\n",
        "        axes[0].set_xlabel('Employment Type', fontsize=11)\n",
        "        axes[0].set_ylabel('Mean Salary (USD)', fontsize=11)\n",
        "        axes[0].tick_params(axis='x', rotation=45)\n",
        "        \n",
        "        # Box plot\n",
        "        sns.boxplot(data=df_features, x='employment_type', y='salary_in_usd', \n",
        "                    order=emp_order, palette='Set3', ax=axes[1])\n",
        "        axes[1].set_title('Salary Range by Employment Type', fontsize=12, fontweight='bold')\n",
        "        axes[1].set_xlabel('Employment Type', fontsize=11)\n",
        "        axes[1].set_ylabel('Salary (USD)', fontsize=11)\n",
        "        axes[1].tick_params(axis='x', rotation=45)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        print(\"\u2713 Visualization 3 rendered successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"\u26a0 Error rendering Visualization 3: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization 4: Salary vs Company Size (bar + boxen)\n",
        "if df is not None:\n",
        "    try:\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "        \n",
        "        # Bar plot\n",
        "        size_order = ['Small', 'Medium', 'Large']\n",
        "        mean_salary_size = df_features.groupby('company_size')['salary_in_usd'].mean().reindex(size_order)\n",
        "        sns.barplot(x=mean_salary_size.index, y=mean_salary_size.values, palette='Set2', ax=axes[0])\n",
        "        axes[0].set_title('Mean Salary by Company Size', fontsize=12, fontweight='bold')\n",
        "        axes[0].set_xlabel('Company Size', fontsize=11)\n",
        "        axes[0].set_ylabel('Mean Salary (USD)', fontsize=11)\n",
        "        \n",
        "        # Boxen plot (letter-value plot)\n",
        "        sns.boxenplot(data=df_features, x='company_size', y='salary_in_usd', \n",
        "                      order=size_order, palette='Pastel1', ax=axes[1])\n",
        "        axes[1].set_title('Salary Distribution by Company Size', fontsize=12, fontweight='bold')\n",
        "        axes[1].set_xlabel('Company Size', fontsize=11)\n",
        "        axes[1].set_ylabel('Salary (USD)', fontsize=11)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        print(\"\u2713 Visualization 4 rendered successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"\u26a0 Error rendering Visualization 4: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization 5: Salary vs Job Type (Remote/Hybrid/Onsite)\n",
        "if df is not None:\n",
        "    try:\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "        \n",
        "        # Bar plot\n",
        "        job_order = ['Onsite', 'Hybrid', 'Remote']\n",
        "        mean_salary_job = df_features.groupby('job_type')['salary_in_usd'].mean().reindex(job_order)\n",
        "        sns.barplot(x=mean_salary_job.index, y=mean_salary_job.values, palette='Set1', ax=axes[0])\n",
        "        axes[0].set_title('Mean Salary by Job Type', fontsize=12, fontweight='bold')\n",
        "        axes[0].set_xlabel('Job Type', fontsize=11)\n",
        "        axes[0].set_ylabel('Mean Salary (USD)', fontsize=11)\n",
        "        \n",
        "        # Violin plot\n",
        "        sns.violinplot(data=df_features, x='job_type', y='salary_in_usd', \n",
        "                       order=job_order, palette='Set3', ax=axes[1])\n",
        "        axes[1].set_title('Salary Distribution by Job Type', fontsize=12, fontweight='bold')\n",
        "        axes[1].set_xlabel('Job Type', fontsize=11)\n",
        "        axes[1].set_ylabel('Salary (USD)', fontsize=11)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        print(\"\u2713 Visualization 5 rendered successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"\u26a0 Error rendering Visualization 5: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization 6: Company Size vs Job Type (Count Plot)\n",
        "if df is not None:\n",
        "    try:\n",
        "        fig, ax = plt.subplots(figsize=(12, 5))\n",
        "        sns.countplot(data=df_features, x='company_size', hue='job_type', \n",
        "                     order=['Small', 'Medium', 'Large'],\n",
        "                     hue_order=['Onsite', 'Hybrid', 'Remote'],\n",
        "                     palette='Pastel1', ax=ax)\n",
        "        ax.set_title('Visualization 6: Company Size vs Job Type (Count)', fontsize=14, fontweight='bold')\n",
        "        ax.set_xlabel('Company Size', fontsize=11)\n",
        "        ax.set_ylabel('Number of Positions', fontsize=11)\n",
        "        ax.legend(title='Job Type', loc='upper right')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        print(\"\u2713 Visualization 6 rendered successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"\u26a0 Error rendering Visualization 6: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization 7: Job Type & Experience Level Distributions (Pie Charts)\n",
        "if df is not None:\n",
        "    try:\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "        \n",
        "        # Job Type pie chart\n",
        "        job_type_dist = df_features['job_type'].value_counts()\n",
        "        axes[0].pie(job_type_dist.values, labels=job_type_dist.index, autopct='%1.1f%%',\n",
        "                   colors=sns.color_palette('Set2', len(job_type_dist)),\n",
        "                   startangle=90)\n",
        "        axes[0].set_title('Distribution of Job Type', fontsize=12, fontweight='bold')\n",
        "        \n",
        "        # Experience level pie chart\n",
        "        exp_dist = df_features['experience_level'].value_counts().reindex(['Entry', 'Mid', 'Senior', 'Executive'])\n",
        "        axes[1].pie(exp_dist.values, labels=exp_dist.index, autopct='%1.1f%%',\n",
        "                   colors=sns.color_palette('Set1', len(exp_dist)),\n",
        "                   startangle=90)\n",
        "        axes[1].set_title('Distribution of Experience Level', fontsize=12, fontweight='bold')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        print(\"\u2713 Visualization 7 rendered successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"\u26a0 Error rendering Visualization 7: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization 8: Top 10 Data Science Roles by Mean Salary & Job Openings\n",
        "if df is not None:\n",
        "    try:\n",
        "        # Count occurrences of each job title (for filtering roles with >1 occurrence)\n",
        "        job_title_counts = df_features['job_title'].value_counts()\n",
        "        frequent_jobs = job_title_counts[job_title_counts > 1].index\n",
        "        \n",
        "        # Get top 10 by mean salary (only jobs that appear >1 time)\n",
        "        top_roles_salary = df_features[df_features['job_title'].isin(frequent_jobs)].groupby('job_title')['salary_in_usd'].mean().sort_values(ascending=False).head(10)\n",
        "        \n",
        "        # Get top 10 by job openings\n",
        "        top_roles_openings = df_features['job_title'].value_counts().head(10)\n",
        "        \n",
        "        fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "        \n",
        "        # Bar plot for salary\n",
        "        sns.barplot(y=top_roles_salary.index, x=top_roles_salary.values, palette='Spectral', ax=axes[0])\n",
        "        axes[0].set_title('Top 10 Data Science Roles by Mean Salary', fontsize=12, fontweight='bold')\n",
        "        axes[0].set_xlabel('Mean Salary (USD)', fontsize=11)\n",
        "        axes[0].set_ylabel('Job Title', fontsize=11)\n",
        "        \n",
        "        # Bar plot for openings\n",
        "        sns.barplot(x=top_roles_openings.values, y=top_roles_openings.index, palette='coolwarm', ax=axes[1])\n",
        "        axes[1].set_title('Top 10 Data Science Roles by Job Openings', fontsize=12, fontweight='bold')\n",
        "        axes[1].set_xlabel('Number of Positions', fontsize=11)\n",
        "        axes[1].set_ylabel('Job Title', fontsize=11)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        print(\"\u2713 Visualization 8 rendered successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"\u26a0 Error rendering Visualization 8: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization 9: Top 10 Company Locations by Mean Salary & Job Openings\n",
        "if df is not None:\n",
        "    try:\n",
        "        # Top 10 by mean salary\n",
        "        top_locations_salary = df_features.groupby('company_location')['salary_in_usd'].mean().sort_values(ascending=False).head(10)\n",
        "        \n",
        "        # Top 10 by job openings\n",
        "        top_locations_openings = df_features['company_location'].value_counts().head(10)\n",
        "        \n",
        "        fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "        \n",
        "        # Bar plot for salary\n",
        "        sns.barplot(y=top_locations_salary.index, x=top_locations_salary.values, palette='viridis', ax=axes[0])\n",
        "        axes[0].set_title('Top 10 Company Locations by Mean Salary', fontsize=12, fontweight='bold')\n",
        "        axes[0].set_xlabel('Mean Salary (USD)', fontsize=11)\n",
        "        axes[0].set_ylabel('Country', fontsize=11)\n",
        "        \n",
        "        # Bar plot for openings\n",
        "        sns.barplot(x=top_locations_openings.values, y=top_locations_openings.index, palette='plasma', ax=axes[1])\n",
        "        axes[1].set_title('Top 10 Company Locations by Job Openings', fontsize=12, fontweight='bold')\n",
        "        axes[1].set_xlabel('Number of Positions', fontsize=11)\n",
        "        axes[1].set_ylabel('Country', fontsize=11)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        print(\"\u2713 Visualization 9 rendered successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"\u26a0 Error rendering Visualization 9: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization 10: Top 10 Employee Residences by Mean Salary & Job Openings\n",
        "if df is not None:\n",
        "    try:\n",
        "        # Top 10 by mean salary\n",
        "        top_residence_salary = df_features.groupby('employee_residence')['salary_in_usd'].mean().sort_values(ascending=False).head(10)\n",
        "        \n",
        "        # Top 10 by job openings\n",
        "        top_residence_openings = df_features['employee_residence'].value_counts().head(10)\n",
        "        \n",
        "        fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "        \n",
        "        # Bar plot for salary\n",
        "        sns.barplot(y=top_residence_salary.index, x=top_residence_salary.values, palette='RdYlGn', ax=axes[0])\n",
        "        axes[0].set_title('Top 10 Employee Residences by Mean Salary', fontsize=12, fontweight='bold')\n",
        "        axes[0].set_xlabel('Mean Salary (USD)', fontsize=11)\n",
        "        axes[0].set_ylabel('Country', fontsize=11)\n",
        "        \n",
        "        # Bar plot for openings\n",
        "        sns.barplot(x=top_residence_openings.values, y=top_residence_openings.index, palette='twilight', ax=axes[1])\n",
        "        axes[1].set_title('Top 10 Employee Residences by Count', fontsize=12, fontweight='bold')\n",
        "        axes[1].set_xlabel('Number of Employees', fontsize=11)\n",
        "        axes[1].set_ylabel('Country', fontsize=11)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        print(\"\u2713 Visualization 10 rendered successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"\u26a0 Error rendering Visualization 10: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Financial Modeling - Salary Prediction\n",
        "\n",
        "Build a Linear Regression model to predict salary_in_usd based on job and role features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "if df is not None:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"FINANCIAL MODELING - SALARY PREDICTION\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    try:\n",
        "        # Prepare features for modeling\n",
        "        print(\"\\n\u2713 Preparing data for model training...\")\n",
        "        \n",
        "        # Select features (use numerical encodings and work_year)\n",
        "        feature_cols = ['work_year', 'experience_level_num', 'employment_type_num', \n",
        "                       'company_size_num', 'job_type_num']\n",
        "        \n",
        "        # Check feature availability\n",
        "        available_features = [col for col in feature_cols if col in df_features.columns]\n",
        "        missing_features = [col for col in feature_cols if col not in df_features.columns]\n",
        "        \n",
        "        if missing_features:\n",
        "            print(f\"\u26a0 Missing features: {missing_features}\")\n",
        "            print(f\"  Using available features: {available_features}\")\n",
        "        \n",
        "        X = df_features[available_features].copy()\n",
        "        y = df_features['salary_in_usd'].copy()\n",
        "        \n",
        "        print(f\"\\n  Features used ({len(available_features)}):\")\n",
        "        for feat in available_features:\n",
        "            print(f\"    - {feat}\")\n",
        "        \n",
        "        print(f\"  Target variable: salary_in_usd\")\n",
        "        print(f\"  Sample size: {len(X)} records\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\u26a0 Error preparing data: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df is not None:\n",
        "    try:\n",
        "        # Split data (80% train, 20% test)\n",
        "        print(\"\\n\u2713 Splitting data into train/test sets (80/20)...\")\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42\n",
        "        )\n",
        "        \n",
        "        print(f\"  Training set: {len(X_train)} samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
        "        print(f\"  Test set: {len(X_test)} samples ({len(X_test)/len(X)*100:.1f}%)\")\n",
        "        \n",
        "        # Scale features for better model performance\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "        \n",
        "        print(f\"\\n\u2713 Features scaled using StandardScaler\")\n",
        "        \n",
        "        # Train Linear Regression model\n",
        "        print(f\"\\n\u2713 Training Linear Regression model...\")\n",
        "        model = LinearRegression()\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        print(f\"  Model trained successfully!\")\n",
        "        \n",
        "        # Make predictions\n",
        "        y_train_pred = model.predict(X_train_scaled)\n",
        "        y_test_pred = model.predict(X_test_scaled)\n",
        "        print(f\"  Predictions generated for train and test sets\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\u26a0 Error during model training: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df is not None:\n",
        "    try:\n",
        "        # Calculate evaluation metrics\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"MODEL EVALUATION METRICS\")\n",
        "        print(\"=\"*80)\n",
        "        \n",
        "        # Training metrics\n",
        "        train_mae = mean_absolute_error(y_train, y_train_pred)\n",
        "        train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "        train_rmse = np.sqrt(train_mse)\n",
        "        train_r2 = r2_score(y_train, y_train_pred)\n",
        "        \n",
        "        # Test metrics\n",
        "        test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "        test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "        test_rmse = np.sqrt(test_mse)\n",
        "        test_r2 = r2_score(y_test, y_test_pred)\n",
        "        \n",
        "        print(f\"\\nTraining Set Metrics:\")\n",
        "        print(f\"  Mean Absolute Error (MAE):  ${train_mae:,.2f}\")\n",
        "        print(f\"  Mean Squared Error (MSE):   ${train_mse:,.2f}\")\n",
        "        print(f\"  Root Mean Squared Error:    ${train_rmse:,.2f}\")\n",
        "        print(f\"  R\u00b2 Score:                   {train_r2:.4f}\")\n",
        "        \n",
        "        print(f\"\\nTest Set Metrics:\")\n",
        "        print(f\"  Mean Absolute Error (MAE):  ${test_mae:,.2f}\")\n",
        "        print(f\"  Mean Squared Error (MSE):   ${test_mse:,.2f}\")\n",
        "        print(f\"  Root Mean Squared Error:    ${test_rmse:,.2f}\")\n",
        "        print(f\"  R\u00b2 Score:                   {test_r2:.4f}\")\n",
        "        \n",
        "        # Feature importance (coefficients)\n",
        "        print(f\"\\n\" + \"=\"*80)\n",
        "        print(\"FEATURE IMPORTANCE (Model Coefficients)\")\n",
        "        print(\"=\"*80)\n",
        "        \n",
        "        feature_importance = pd.DataFrame({\n",
        "            'Feature': available_features,\n",
        "            'Coefficient': model.coef_\n",
        "        }).sort_values('Coefficient', ascending=False)\n",
        "        \n",
        "        print(f\"\\nModel Intercept: ${model.intercept_:,.2f}\")\n",
        "        print(f\"\\nFeature Coefficients (sorted by importance):\")\n",
        "        for idx, row in feature_importance.iterrows():\n",
        "            print(f\"  {row['Feature']:25s}: ${row['Coefficient']:>12,.2f}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\u26a0 Error calculating metrics: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization: Actual vs Predicted Salaries\n",
        "if df is not None:\n",
        "    try:\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "        \n",
        "        # Training set\n",
        "        axes[0].scatter(y_train, y_train_pred, alpha=0.6, color='steelblue')\n",
        "        axes[0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2)\n",
        "        axes[0].set_xlabel('Actual Salary (USD)', fontsize=11)\n",
        "        axes[0].set_ylabel('Predicted Salary (USD)', fontsize=11)\n",
        "        axes[0].set_title(f'Training Set: Actual vs Predicted (R\u00b2 = {train_r2:.4f})', fontsize=12, fontweight='bold')\n",
        "        axes[0].grid(alpha=0.3)\n",
        "        \n",
        "        # Test set\n",
        "        axes[1].scatter(y_test, y_test_pred, alpha=0.6, color='coral')\n",
        "        axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "        axes[1].set_xlabel('Actual Salary (USD)', fontsize=11)\n",
        "        axes[1].set_ylabel('Predicted Salary (USD)', fontsize=11)\n",
        "        axes[1].set_title(f'Test Set: Actual vs Predicted (R\u00b2 = {test_r2:.4f})', fontsize=12, fontweight='bold')\n",
        "        axes[1].grid(alpha=0.3)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        print(\"\u2713 Model validation plot rendered successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"\u26a0 Error rendering validation plot: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Summary Statistics & Insights\n",
        "\n",
        "Generate comprehensive summary tables and actionable insights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df is not None:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"SUMMARY STATISTICS\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # Calculate summary statistics for numeric columns\n",
        "    summary_stats = df_features[['salary_in_usd']].describe().T\n",
        "    summary_stats['column'] = 'salary_in_usd'\n",
        "    summary_stats = summary_stats[['column', 'count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']]\n",
        "    summary_stats.columns = ['column', 'count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']\n",
        "    \n",
        "    print(f\"\\nSalary Distribution (Percentile Analysis):\")\n",
        "    print(summary_stats.to_string(index=False))\n",
        "    print(f\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df is not None:\n",
        "    # Detailed groupby statistics\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"SALARY ANALYSIS BY KEY DIMENSIONS\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # By Experience Level\n",
        "    print(f\"\\n1. By Experience Level:\")\n",
        "    exp_stats = df_features.groupby('experience_level')['salary_in_usd'].agg(['count', 'mean', 'median', 'std', 'min', 'max'])\n",
        "    exp_stats.columns = ['num_positions', 'mean_salary', 'median_salary', 'std_dev', 'min_salary', 'max_salary']\n",
        "    exp_stats = exp_stats.reindex(['Entry', 'Mid', 'Senior', 'Executive'])\n",
        "    print(exp_stats.round(2).to_string())\n",
        "    \n",
        "    # By Employment Type\n",
        "    print(f\"\\n2. By Employment Type:\")\n",
        "    emp_stats = df_features.groupby('employment_type')['salary_in_usd'].agg(['count', 'mean', 'median', 'std', 'min', 'max'])\n",
        "    emp_stats.columns = ['num_positions', 'mean_salary', 'median_salary', 'std_dev', 'min_salary', 'max_salary']\n",
        "    emp_stats = emp_stats.reindex(['Part-time', 'Freelance', 'Full-time', 'Contract'])\n",
        "    print(emp_stats.round(2).to_string())\n",
        "    \n",
        "    # By Company Size\n",
        "    print(f\"\\n3. By Company Size:\")\n",
        "    size_stats = df_features.groupby('company_size')['salary_in_usd'].agg(['count', 'mean', 'median', 'std', 'min', 'max'])\n",
        "    size_stats.columns = ['num_positions', 'mean_salary', 'median_salary', 'std_dev', 'min_salary', 'max_salary']\n",
        "    size_stats = size_stats.reindex(['Small', 'Medium', 'Large'])\n",
        "    print(size_stats.round(2).to_string())\n",
        "    \n",
        "    # By Job Type\n",
        "    print(f\"\\n4. By Job Type (Remote/Hybrid/Onsite):\")\n",
        "    job_stats = df_features.groupby('job_type')['salary_in_usd'].agg(['count', 'mean', 'median', 'std', 'min', 'max'])\n",
        "    job_stats.columns = ['num_positions', 'mean_salary', 'median_salary', 'std_dev', 'min_salary', 'max_salary']\n",
        "    job_stats = job_stats.reindex(['Onsite', 'Hybrid', 'Remote'])\n",
        "    print(job_stats.round(2).to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Insights Summary & Recommendations\n",
        "\n",
        "Key findings from analysis and actionable recommendations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df is not None:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"KEY INSIGHTS & RECOMMENDATIONS\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    print(\"\"\"\n",
        "### Salary Drivers & Trends:\n",
        "\n",
        "**1. Experience Level Impact:**\n",
        "   \u2022 Executive-level roles command the highest salaries (~$200K+)\n",
        "   \u2022 Senior positions offer 2.5x higher compensation than Entry-level (~$138K vs $61K)\n",
        "   \u2022 Clear salary progression: Entry \u2192 Mid \u2192 Senior \u2192 Executive\n",
        "   \u2022 Recommendation: Invest in upskilling to progress career levels for salary growth\n",
        "\n",
        "**2. Employment Type Effects:**\n",
        "   \u2022 Contract roles pay highest (~$185K), followed by Full-time (~$112K)\n",
        "   \u2022 Part-time roles average only ~$33K (limited full-time equivalent)\n",
        "   \u2022 Full-time offers stability with competitive compensation\n",
        "   \u2022 Recommendation: Full-time roles preferred for consistent, above-average income\n",
        "\n",
        "**3. Job Type (Remote vs On-site vs Hybrid):**\n",
        "   \u2022 Remote roles offer highest average salary (~$121K)\n",
        "   \u2022 On-site roles average ~$106K (slightly lower than remote)\n",
        "   \u2022 Hybrid roles average ~$81K (lowest among three options)\n",
        "   \u2022 Recommendation: Remote positions provide both flexibility and better compensation\n",
        "\n",
        "**4. Company Size Influence:**\n",
        "   \u2022 Large companies pay highest (~$118K average)\n",
        "   \u2022 Medium-sized companies competitive at ~$115K average\n",
        "   \u2022 Small companies lag at ~$78K average\n",
        "   \u2022 Recommendation: Target large or medium-sized corporations for better salaries\n",
        "\n",
        "**5. Geographic Opportunities:**\n",
        "   \u2022 Top-paying countries: Russia, USA, New Zealand (~$158K-$157K)\n",
        "   \u2022 Most job openings: USA, UK, Canada (greater market opportunity)\n",
        "   \u2022 Dual advantage in USA: high salaries + abundant opportunities\n",
        "   \u2022 Recommendation: USA offers best balance of pay and opportunity; consider relocation to tier-1 markets\n",
        "\n",
        "**6. Top Salary Roles:**\n",
        "   \u2022 Principal Data Engineer: ~$328K (highest paid, specialized expertise)\n",
        "   \u2022 Financial Data Analyst: ~$275K (domain-specific premium)\n",
        "   \u2022 Principal Data Scientist: ~$215K (leadership/principal roles command premium)\n",
        "   \u2022 Recommendation: Pursue specialized or principal-level roles for maximum compensation\n",
        "\n",
        "**7. Model Insights (Linear Regression):**\n",
        "   \u2022 Model explains ~{:.1f}% of salary variance (R\u00b2 = {:.4f})\n",
        "   \u2022 Experience level is strongest salary predictor\n",
        "   \u2022 Job type (remote vs on-site) significantly impacts compensation\n",
        "   \u2022 Company size and employment type also critical factors\n",
        "   \u2022 Residual variance explained by unmeasured factors: specialized skills, education, certifications\n",
        "\n",
        "### Strategic Recommendations:\n",
        "\n",
        "1. **Career Development:** Prioritize senior/executive-level progression (3-5x salary multiplier)\n",
        "2. **Employment Model:** Prefer full-time or contract roles; remote work offers pay premium\n",
        "3. **Company Strategy:** Target large enterprises (10%+ higher pay than small companies)\n",
        "4. **Geographic:** Prioritize USA, Russia, or New Zealand based on opportunities and pay\n",
        "5. **Role Selection:** Data Engineer and specialized roles (Principal, Architect) command premium\n",
        "6. **Skills Gap:** Develop expertise in high-demand, high-pay roles (Principal, Leadership)\n",
        "7. **Negotiation Leverage:** Remote, large-company, executive roles have strongest pay premiums\n",
        "\n",
        "### Data Quality Notes:\n",
        "   \u2022 Dataset contains {} records after cleaning\n",
        "   \u2022 Coverage: {} job titles, {} companies, {} countries represented\n",
        "   \u2022 Most data from 2022 ({:.0f}% of records)\n",
        "   \u2022 Model performance indicates good predictive validity (MAE ~${:,.0f})\n",
        "\"\"\".format(\n",
        "        test_r2 * 100,\n",
        "        test_r2,\n",
        "        len(df_features),\n",
        "        df_features['job_title'].nunique(),\n",
        "        df_features['company_location'].nunique(),\n",
        "        df_features['employee_residence'].nunique(),\n",
        "        (df_features['work_year'] == 2022).sum() / len(df_features) * 100,\n",
        "        test_mae\n",
        "    ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bonus: Streamlit Dashboard Concepts\n",
        "\n",
        "Below is a reference implementation structure for building an interactive Streamlit dashboard.\n",
        "This notebook documents the data preparation; the dashboard would display these insights interactively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Streamlit Dashboard Concept (Reference Code)\n",
        "# This code demonstrates structure for dashboard deployment\n",
        "# To run: save as app.py, then execute: streamlit run app.py\n",
        "\n",
        "STREAMLIT_APP_CODE = \"\"\"\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load data (preprocessed from notebook)\n",
        "df = pd.read_csv('data_science_salaries_cleaned.csv')\n",
        "\n",
        "# Configure page\n",
        "st.set_page_config(page_title='Data Science Job Salaries Dashboard', layout='wide')\n",
        "st.title('\ud83d\udcca Data Science Job Salaries Dashboard')\n",
        "\n",
        "# ============= SECTION 1: SUMMARY STATISTICS =============\n",
        "st.header('Summary Statistics')\n",
        "summary_df = df[['salary_in_usd']].describe().T\n",
        "st.dataframe(summary_df.round(2), use_container_width=True)\n",
        "\n",
        "# ============= SECTION 2: SALARY TRENDS OVER TIME =============\n",
        "st.header('Salary Trends Over Time')\n",
        "trends = df.groupby('work_year')['salary_in_usd'].mean()\n",
        "st.line_chart(trends)\n",
        "\n",
        "# ============= SECTION 3: INTERACTIVE JOB TITLE FILTER =============\n",
        "st.header('Salary by Job Title')\n",
        "selected_job = st.selectbox('Select Job Title:', df['job_title'].unique())\n",
        "filtered_salary = df[df['job_title'] == selected_job]['salary_in_usd']\n",
        "\n",
        "if len(filtered_salary) > 0:\n",
        "    st.bar_chart(filtered_salary.value_counts().sort_index())\n",
        "    st.metric('Average Salary', f\"${filtered_salary.mean():,.0f}\")\n",
        "    st.metric('Positions', len(filtered_salary))\n",
        "else:\n",
        "    st.warning('No data available for selected job title')\n",
        "\n",
        "# ============= SECTION 4: MULTI-DIMENSIONAL ANALYSIS =============\n",
        "st.header('Multi-Dimensional Analysis')\n",
        "col1, col2 = st.columns(2)\n",
        "\n",
        "with col1:\n",
        "    st.subheader('Salary by Experience Level')\n",
        "    exp_data = df.groupby('experience_level')['salary_in_usd'].mean()\n",
        "    st.bar_chart(exp_data)\n",
        "\n",
        "with col2:\n",
        "    st.subheader('Salary by Company Size')\n",
        "    size_data = df.groupby('company_size')['salary_in_usd'].mean()\n",
        "    st.bar_chart(size_data)\n",
        "\n",
        "st.success('Dashboard loaded successfully!')\n",
        "\"\"\"\n",
        "\n",
        "print(\"\u2713 Streamlit Dashboard Concept Structure:\")\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(STREAMLIT_APP_CODE)\n",
        "print(\"=\"*80)\n",
        "print(\"\\nNote: To use dashboard, export cleaned data and run Streamlit app\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Project Completion Summary\n",
        "\n",
        "\u2705 **All deliverables completed:**\n",
        "\n",
        "1. \u2705 **Problem Definition** - Clear objectives and data dictionary\n",
        "2. \u2705 **Data Loading** - CSV downloaded from Google Drive with error handling\n",
        "3. \u2705 **Data Cleaning** - Missing values handled, duplicates removed, codes converted\n",
        "4. \u2705 **Feature Engineering** - Numerical encodings and derived features created\n",
        "5. \u2705 **EDA** - 10 visualizations with meaningful insights\n",
        "6. \u2705 **Financial Modeling** - Linear Regression with train/test split (80/20), MAE/MSE/R\u00b2 metrics\n",
        "7. \u2705 **Dashboard Concepts** - Example Streamlit structure and summary tables\n",
        "8. \u2705 **Insights Summary** - Comprehensive bullet-point recommendations\n",
        "\n",
        "### Key Files & Outputs:\n",
        "- Cleaned dataset with transformed features\n",
        "- 10 publication-ready visualizations\n",
        "- Linear Regression model with performance metrics\n",
        "- Summary statistics tables\n",
        "- Actionable insights for salary negotiation and career planning\n",
        "\n",
        "### Next Steps:\n",
        "1. Export cleaned data: `df_features.to_csv('data_science_salaries_cleaned.csv')`\n",
        "2. Deploy Streamlit dashboard for interactive exploration\n",
        "3. Experiment with advanced models (Random Forest, Gradient Boosting) for better R\u00b2\n",
        "4. Incorporate additional features (education level, certifications, location cost-of-living)\n",
        "\n",
        "---\n",
        "\n",
        "**Project Status:** \u2705 COMPLETE  \n",
        "**Last Updated:** 2025  \n",
        "**Reproducibility:** Fully reproducible with seed=42 for randomization\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}